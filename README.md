# <img height=34 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Hand%20gestures/Handshake.png"/> Awesome Diffusion Ã— Autoregression (DiffxAR)
A curated list of hybrid Diffusion + Autoregressive (DiffxAR) models for language, reasoning, and robots.

Note: Currently, this repository is under construction, some tags may be wrong or unclear, and some important papers may not be covered. We welcome everyone's comments and contributions!

---

## <img height=28 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Smiling%20Face%20with%20Hearts.png"/> Legend


**Diffusion space**

- ğŸ§± Discrete diffusion (token / categorical space, e.g., D3PM, dLLM).
- ğŸŒŠ Continuous / latent diffusion (continuous states or learned latents).

**How diffusion Ã— autoregression interact**

- ğŸ§© Plannerâ€“executor hybrids (Decompose â€œthinks / plansâ€ & â€œspeaks / executesâ€).
- ğŸªœ Training / objective bridges (convert AR LMs into DLMs, shared objectives, distillation).
- âš™ï¸ Decoding & efficiency hybrids (blockwise decoding, diffusion-forcing, semi-AR decoding).

**Domains**

- ğŸ§  Reasoning & planning (math, logic, tool-use, multi-step CoT).
- ğŸ¤– Embodied / VLA / robotics (visionâ€“languageâ€“action, robot policies).
- ğŸ§ª AI4Science & scientific modeling (molecules, materials, proteins, scientific reasoning).
- âš–ï¸ Surveys & overviews.

---

## <img height=34 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Smiling%20Face%20with%20Sunglasses.png"/> Paper List



### 2025

- 2025 ğŸ§±ğŸ§©ğŸ§  Planner and Executor: Collaboration Between Discrete Diffusion and Autoregressive Models in Reasoning. [arXiv:2510.15244](https://arxiv.org/abs/2510.15244)
- 2025 ğŸŒŠğŸ§©ğŸ§  LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning. [arXiv:2510.04573](https://arxiv.org/abs/2510.04573)
- 2025 ğŸ§±ğŸ§© Planned Diffusion: A Guiding Diffusion Language Model via Planning. [arXiv:2510.18087](https://arxiv.org/abs/2510.18087)
- 2025 ğŸ§±ğŸ§©ğŸ§  TiDAR: Think in Diffusion, Talk in Autoregression. [arXiv:2511.08923](https://arxiv.org/abs/2511.08923)
- 2025 ğŸ§±ğŸªœâš™ï¸ D2F: Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing. [arXiv:2508.09192](https://arxiv.org/abs/2508.09192)
- 2025 ğŸ§±ğŸ§©âš™ï¸ HEX: Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts. [arXiv:2510.05040](https://arxiv.org/abs/2510.05040)
- 2025 ğŸ§±ğŸªœ SDAR: A Synergistic Diffusion-Autoregression Paradigm for Scalable Sequence Generation. [arXiv:2510.06303](https://arxiv.org/abs/2510.06303)
- 2025 ğŸ§±âš™ï¸ Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models. [arXiv:2503.09573](https://arxiv.org/abs/2503.09573)
- 2025 ğŸ§±âš™ï¸ Sequential Diffusion Language Models. [arXiv:2509.24007](https://arxiv.org/abs/2509.24007)
- 2025 ğŸ§±ğŸªœâš™ï¸ Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding. [arXiv:2508.19529](https://arxiv.org/abs/2508.19529)
- 2025 ğŸ§±ğŸ§  DiffTOD: Planning with Diffusion Models for Target-Oriented Dialogue Systems. [ACL 2025](https://aclanthology.org/2025.acl-long.993/)
- 2025 ğŸ§±ğŸªœ Energy-Based Diffusion Language Models for Text Generation. [arXiv:2410.21357](https://arxiv.org/abs/2410.21357)
- 2025 ğŸ§±âš–ï¸ On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond. [arXiv:2510.06190](https://arxiv.org/abs/2510.06190)
- 2025 ğŸ§±ğŸªœ Non-Markovian Discrete Diffusion with Causal Language Models. [arXiv:2502.09767](https://arxiv.org/abs/2502.09767)
- 2025 ğŸŒŠğŸ§©ğŸ¤– HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model. [arXiv:2503.10631](https://arxiv.org/abs/2503.10631)


### 2024

- 2024 ğŸ§±ğŸ§© Diffusion Guided Language Modeling. [arXiv:2408.04220](https://arxiv.org/abs/2408.04220)
- 2024 ğŸ§±ğŸ§  Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning. [arXiv:2410.14157](https://arxiv.org/abs/2410.14157)
- 2024 ğŸ§±âš™ï¸ Beyond Autoregression: Fast LLMs via Self-Distillation Through Time. [arXiv:2410.21035](https://arxiv.org/abs/2410.21035)
- 2024 ğŸ§±ğŸªœ Scaling Diffusion Language Models via Adaptation from Autoregressive Models. [arXiv:2410.17891](https://arxiv.org/abs/2410.17891)
- 2024 ğŸ§±ğŸ§  Diffusion-of-Thought: Chain-of-Thought Reasoning in Diffusion Language Models. [arXiv:2402.07754](https://arxiv.org/abs/2402.07754)
- 2024 ğŸ§± D3PM: Structured Denoising Diffusion Models in Discrete State-Spaces. [arXiv:2107.03006](https://arxiv.org/abs/2107.03006)
- 2024 ğŸŒŠğŸ§©ğŸ¤– Diffusion-VLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression. [arXiv:2412.03293](https://arxiv.org/abs/2412.03293)


### 2023

- 2023 ğŸ§±ğŸ§© AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation. [arXiv:2305.09515](https://arxiv.org/abs/2305.09515)
- 2023 ğŸ§± A Reparameterized Discrete Diffusion Model for Text Generation. [arXiv:2302.05737](https://arxiv.org/abs/2302.05737)
- 2023 ğŸ§± Sequential Data Generation with Groupwise Diffusion Process. [arXiv:2310.01400](https://arxiv.org/abs/2310.01400)
- 2023 ğŸŒŠğŸ§© PLANNER: Enhancing Paragraph Generation with a Latent Language Diffusion Model. [arXiv:2306.02531](https://arxiv.org/abs/2306.02531)

### 2022

- 2022 ğŸŒŠğŸ§© Latent Diffusion for Language Generation. [arXiv:2212.09462](https://arxiv.org/abs/2212.09462)
- 2022 ğŸ§± SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control. [arXiv:2210.17432](https://arxiv.org/abs/2210.17432)
- 2022 ğŸŒŠ Diffusion-LM Improves Controllable Text Generation. [arXiv:2205.14217](https://arxiv.org/abs/2205.14217)
- 2022 ğŸ§± D3PMs: Denoising Diffusion Probabilistic Models for Discrete Data. [arXiv:2107.03006](https://arxiv.org/abs/2107.03006)

---
## <img height=34 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Hammer%20and%20Wrench.png"/> Want to Contribute?

We welcome contributions! Please feel free to submit a PR or open an issue if you'd like to add new papers, tools, or correct any mistakes.

### âœ… Guidelines

- Only add papers that **explicitly connect diffusion and autoregression** in **architecture, training, or decoding**.
- Use consistent formatting:  
  `YEAR ICONS Title. [arXiv:ID](https://arxiv.org/abs/ID)`
- Try to tag each paper with:
  - one of **ğŸ§± / ğŸŒŠ**,
  - whether it is **ğŸ§© / ğŸªœ / âš™ï¸**, and
  - optional domain tags **ğŸ§  / ğŸ¤– / ğŸ§ª / âš–ï¸**.
- Prefer papers with an **arXiv entry** so that every bullet has a stable link.
- If you add a new domain (e.g. speech, music, code), consider adding a short note in the PR explaining how diffusion and AR interact in that setting.
