# <img height=34 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Hand%20gestures/Handshake.png"/> Awesome Diffusion Ã— Autoregression (DxAR)
A curated list of hybrid Diffusion + Autoregressive (ARxDiff) models for language, reasoning, and robots.

<img height=220 src="./img/dxar.png" alt="Diffusion Ã— Autoregression hybrid models illustration"/>

---

## <img height=28 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Nerd%20Face.png"/> Legend

- ğŸ”— **Hybrid (Diffusion Ã— Autoregression)** â€“ explicit collaboration.
- ğŸ’­ **Diffusion-style generation** â€“ masked / block / discrete diffusion.
- ğŸ“ **Autoregressive-style generation** â€“ left-to-right or causal decoding.
- âš¡ **Inference efficiency** â€“ methods focused on faster sampling.

---

## <img height=34 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Smiling%20Face%20with%20Sunglasses.png"/> Paper List

### ğŸ§  Language & Reasoning

Tasks centered on text generation, multi-step reasoning, planning, or tool use.

#### 2025
- 2025 ğŸ”— Planner and Executor: Collaboration Between Discrete Diffusion and Autoregressive Models in Reasoning. [arXiv:2510.15244](https://arxiv.org/abs/2510.15244)
- 2025 ğŸ”— Planned Diffusion: A Guiding Diffusion Language Model via Planning. [arXiv:2510.18087](https://arxiv.org/abs/2510.18087)
- 2025 ğŸ”— TiDAR: Think in Diffusion, Talk in Autoregression. [arXiv:2511.08923](https://arxiv.org/abs/2511.08923)
- 2025 ğŸ”—âš¡ D2F: Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing. [arXiv:2508.09192](https://arxiv.org/abs/2508.09192)
- 2025 ğŸ’­âš¡ Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding. [arXiv:2505.22618](https://arxiv.org/abs/2505.22618)
- 2025 ğŸ’­âš¡ HEX: Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts. [arXiv:2510.05040](https://arxiv.org/abs/2510.05040)

#### 2024
- 2024 ğŸ”— Diffusion Guided Language Modeling. [arXiv:2408.04220](https://arxiv.org/abs/2408.04220)
- 2024 ğŸ’­ğŸ“ Simple and Effective Masked Diffusion Language Models. [arXiv:2406.07524](https://arxiv.org/abs/2406.07524)
- 2024 ğŸ’­ğŸ“ Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration. [arXiv:2410.13201](https://arxiv.org/abs/2410.13201)

#### 2023
- 2023 ğŸ’­ğŸ“ AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation. [arXiv:2305.09515](https://arxiv.org/abs/2305.09515)

#### 2022
- 2022 ğŸ’­ğŸ“ SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control. [arXiv:2210.17432](https://arxiv.org/abs/2210.17432)

---

### ğŸ¤– Embodied / VLA

Agents that perceive, think, and act (visionâ€“languageâ€“action, robot control, visuomotor policies).

#### 2025
- 2025 ğŸ”— HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model. [arXiv:2503.10631](https://arxiv.org/abs/2503.10631)

#### 2024
- 2024 ğŸ”— Diffusion-VLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression. [arXiv:2412.03293](https://arxiv.org/abs/2412.03293)

---

### ğŸ“ Theory & General Frameworks

Conceptual or theoretical work comparing AR vs diffusion or unifying them in a shared view.

#### 2025
- 2025 ğŸ“ On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond. [arXiv:2510.06190](https://arxiv.org/abs/2510.06190)

#### 2023
- 2023 ğŸ“ Sequential Data Generation with Groupwise Diffusion Process. [arXiv:2310.01400](https://arxiv.org/abs/2310.01400)

---

## ğŸ§© Want to Contribute?

We welcome contributions! Please feel free to submit a PR or open an issue if you'd like to add new papers, tools, or correct any mistakes.

### âœ… Guidelines

- Only add papers that **explicitly connect diffusion and autoregression** (model or decoding).
- Use consistent formatting: `YEAR ICONS Title. [arXiv:ID](https://arxiv.org/abs/ID)`.
- Prefer papers with an **arXiv entry** so that every bullet has a stable link.
- If you add new domains (e.g., speech, images, code), consider adding a new section with its own icon.
